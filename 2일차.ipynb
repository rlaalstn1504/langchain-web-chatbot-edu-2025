{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f902d9c1",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "3296e183-ad13-46ba-8048-a04452c81fbb"
        }
      },
      "source": [
        "## 6. 문서 기반 챗봇 (RAG, Retrieval-Augmented Generation)\n",
        "\n",
        "### 왜 RAG가 중요한가?\n",
        "\n",
        "기존의 ChatGPT와 같은 **기본 LLM**은 이미 방대한 데이터를 학습했기 때문에  \n",
        "일반 상식이나 범용 지식에 대해서는 뛰어난 답변을 제공합니다.  \n",
        "하지만 **두 가지 한계**가 존재합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf6d8630",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "9b5c6318-b93f-45d1-b9ce-64b8f7c1a33c"
        }
      },
      "source": [
        "**1. 최신 정보 반영 불가**  \n",
        "  - 모델이 학습된 시점 이후의 정보(예: 2024년 기술 논문, 최근 공정 변경, 신소재 데이터)는 알 수 없음\n",
        "- 예: “2025년 포스코의 신형 TMCP 공정 특성은?” → ChatGPT는 모름\n",
        "\n",
        "**2. 도메인 특화 지식 부족**\n",
        "- 용접, 재료, 반도체, 제약, 법률 등 전문 산업의 내부 문서나 보고서 내용은 LLM 학습 데이터에 포함되어 있지 않음\n",
        "- 예: “9%Ni 강의 GTAW 루트 패스 예열 조건” 같은 질문은 일반 LLM이 정확히 답하지 못함"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdc57bca",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "6fa32322-89e1-483a-bb29-8849acc89a43"
        }
      },
      "source": [
        "### RAG (Retrieval-Augmented Generation)란?\n",
        "\n",
        "**RAG**는 LLM의 한계를 보완하기 위해 외부 문서 검색(Retrieval)과 생성(Generation)을 결합한 기술입니다.  \n",
        "일반적인 작동 순서는 다음과 같습니다.\n",
        "\n",
        "**1. 문서 수집 및 벡터화**\n",
        "- 사내 문서, 논문, 보고서, 표준서 등을 **Embedding(임베딩)** 하여 **벡터DB(Vector Database)** 에 저장합니다.  \n",
        "  예: “AWS D1.1 용접절차”, “9Ni 용접 WPS”, “LNG 탱크 보고서” 등  \n",
        "\n",
        "- 하지만 대부분의 문서는 수십 페이지 이상이기 때문에, **한 번에 임베딩하면 검색 품질이 떨어집니다.**  \n",
        "  따라서 문서를 **의미 단위로 잘라(Split)** 여러 개의 작은 “청크(chunk)”로 나눈 후 임베딩합니다.  \n",
        "  예를 들어, 100페이지짜리 WPS 문서를 문단 단위로 잘라 500개 정도의 벡터로 저장합니다.\n",
        "\n",
        "- 이렇게 나누면 LLM이 질문을 받을 때, 전체 문서가 아닌  \n",
        "  **관련성이 높은 부분(chunk)** 만 찾아서 활용할 수 있으므로  \n",
        "  **검색 정확도와 응답 효율이 크게 향상됩니다.**\n",
        "\n",
        "<img src=\"image/RAG.png\" width=\"600\">\n",
        "\n",
        "**2. 질의(Query) 입력**\n",
        "- 사용자가 질문을 하면, 그 질문 또한 Embedding 되어 벡터DB의 문서들과 **유사도(Similarity)** 를 비교합니다.  \n",
        "- 예를 들어, “9%Ni 강의 루트 패스 예열 온도는?” 이라는 질문이 들어오면  \n",
        "  그와 가장 관련된 문서 조각(Top-k)을 자동으로 검색합니다.\n",
        "\n",
        "**3. 문서 결합**\n",
        "- 검색된 문서 내용을 LLM의 프롬프트에 함께 삽입합니다.  \n",
        "- 이때 “검색 결과를 바탕으로 답변하라”는 지시를 추가하여  \n",
        "  모델이 추측하지 않고 근거를 참고하도록 합니다.\n",
        "\n",
        "\n",
        "**4. 답변 생성**\n",
        "- LLM은 삽입된 문서 내용을 토대로 답변을 생성합니다.  \n",
        "  즉, 단순히 일반적인 추론이 아니라 **실제 문서 근거 기반 답변**을 제공합니다.  \n",
        "- 이를 통해 **지엽적이고 전문적인 질문**에도 신뢰도 높은 응답이 가능합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82142468",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "73c1a850-26a6-416e-b07b-a5ba3a2add3a"
        }
      },
      "source": [
        "### RAG의 핵심 효과\n",
        "\n",
        "| 항목 | 기존 LLM | RAG 적용 후 |\n",
        "|------|-----------|-------------|\n",
        "| **지식 범위** | 사전 학습된 데이터에 한정 | 사내 문서·논문·데이터까지 확장 |\n",
        "| **정확성** | 추측성 답변 가능 (Hallucination) | 근거 기반 답변 |\n",
        "| **갱신성** | 정적 (모델 재학습 필요) | 동적 (벡터DB만 갱신하면 즉시 반영) |\n",
        "| **비용** | 새로 Fine-tuning 필요 | 모델은 그대로, 문서만 추가 |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16d02458",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "3a4f6dd0-435c-4191-b86f-7d7ffb5335ba"
        }
      },
      "source": [
        "#### 예시 ① — 일반 LLM만 사용하는 경우\n",
        "\n",
        "```bash\n",
        "질문: 9%Ni 강 LNG 탱크의 루트 패스 용접 시 예열 온도는?  \n",
        "AI: 9%Ni 강은 극저온용 강재로 알려져 있으며, 일반적으로 저온 인성을 위해 열처리를 수행합니다.\n",
        "(→ 실제 예열 조건은 제시하지 않음, 추측성 답변)\n",
        "```\n",
        "\n",
        "#### 예시 ② — RAG 기반 챗봇의 경우\n",
        "```bash\n",
        "질문: 9%Ni 강 LNG 탱크의 루트 패스 용접 시 예열 온도는?  \n",
        "AI: 이전에 등록된 'POSCO LNG Tank WPS-2024' 문서에 따르면,\n",
        "루트 패스 예열 온도는 80~120°C로 설정되어 있습니다.\n",
        "(이전 패스의 수소 집적 방지를 위해 예열 유지가 필요합니다.)\n",
        "```\n",
        "\n",
        "→ 이처럼 RAG는 단순히 말로 잘하는 AI가 아니라, **근거를 가진 실무형 전문가 챗봇**을 만드는 기술입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd86bd4b",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "dd5b0795-9977-4426-ab7d-2db02e7080ea"
        }
      },
      "source": [
        "### 정리\n",
        "- **RAG는 모델을 다시 학습시키지 않고도, 새로운 지식을 즉시 반영**할 수 있는 구조입니다.  \n",
        "- LLM이 “지식 생성기”라면, RAG는 그 위에 붙는 **“지식 확장기(knowledge extender)”** 입니다.  \n",
        "- 특히 엔지니어링, 제조, 연구개발 분야에서는  \n",
        "  사내 표준서·보고서·규격 문서를 기반으로 RAG 챗봇을 구성하면  \n",
        "  “실무형 QA 비서”를 구현할 수 있습니다.\n",
        "\n",
        "| 구분 | 설명 |\n",
        "|------|------|\n",
        "| **RAG 정의** | Retrieval-Augmented Generation — 검색 기반 생성형 AI |\n",
        "| **핵심 아이디어** | “모델이 모르면 문서에서 찾아서 답하라” |\n",
        "| **필요 이유** | LLM의 한계(최신성·전문화 부족) 보완 |\n",
        "| **핵심 구성요소** | Embedding → Vector DB → Retriever → LLM |\n",
        "| **적용 예시** | 사내 기술 보고서 챗봇, 논문 기반 QA, 품질 기준 상담, 법률/특허 문서 질의응답 |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a852d9a7",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "a1e17d46-6b9b-4328-8a5f-653a56a8fc1b"
        }
      },
      "source": [
        "#### 삼성 메모리 카드 매뉴얼 PDF 기반 질의응답 예제"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3681f912",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "12839433-8fe9-4ea4-8d5a-a84fd754ddf9"
        }
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from dotenv import load_dotenv # .env 파일의 환경변수를 자동으로 불러오기 위한 모듈\n",
        "load_dotenv()  # 실행 시 .env 파일을 찾아 변수들을 환경에 로드\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 1️⃣ PDF 로드\n",
        "# -----------------------------------------------------\n",
        "# Samsung_Card_Manual_Korean_1.3.pdf 파일을 읽어옵니다.\n",
        "# PyPDFLoader는 PDF의 각 페이지를 text로 변환합니다.\n",
        "loader = PyPDFLoader(\"data/Samsung_Card_Manual_Korean_1.3.pdf\")\n",
        "pages = loader.load()  # List[Document] 형태로 반환\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 2️⃣ 텍스트 분할 (chunk 단위)\n",
        "# -----------------------------------------------------\n",
        "# CharacterTextSplitter로 문서를 청크 단위로 쪼갭니다.\n",
        "# chunk_size와 overlap은 retrieval 성능에 영향을 줍니다.\n",
        "splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "docs = splitter.split_documents(pages)\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 3️⃣ 임베딩 생성 및 벡터DB 저장\n",
        "# -----------------------------------------------------\n",
        "# OpenAI Embeddings를 이용해 각 문서 청크를 벡터화하고\n",
        "# FAISS에 저장합니다. (로컬 DB로 빠른 검색 가능)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectordb = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "# 검색기(retriever) 객체 생성\n",
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})  # 상위 3개 유사 문서 검색\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 4️⃣ 프롬프트 템플릿 정의\n",
        "# -----------------------------------------------------\n",
        "# 사용자의 질문과 검색된 문서를 결합해 LLM에 전달할 프롬프트를 구성합니다.\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "너는 삼성전자 메모리카드 매뉴얼에 대한 전문 어시스턴트이다.\n",
        "다음의 참고 문서를 바탕으로 질문에 정확하게 답하라.\n",
        "\n",
        "[참고문서]\n",
        "{context}\n",
        "\n",
        "[질문]\n",
        "{question}\n",
        "\n",
        "한글로 간결하고 정확하게 답변하라.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6695f505",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "64eb4f85-764b-4c21-9729-53d9f14eb00d"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "질문: 이 유틸리티는 동시에 몇 개의 메모리카드나 UFD를 인식할 수 있나?\n",
            "답변: 이 유틸리티는 동시에 최대 8개의 메모리 카드나 UFD를 인식할 수 있습니다.\n"
          ]
        }
      ],
      "source": [
        "# LCEL(Runnable Sequence) 문법을 이용하여 pipeline을 정의\n",
        "# Retriever로 문서를 검색하고, prompt로 결합한 뒤 LLM으로 생성하는 구조\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}  # 입력을 question으로 받아 retriever 검색\n",
        "    | prompt                                                    # prompt에 삽입\n",
        "    | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)            # OpenAI LLM 호출\n",
        ")\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 6️⃣ 질의 수행\n",
        "# -----------------------------------------------------\n",
        "# 실제로 사용자가 질문을 던지는 부분입니다.\n",
        "query = \"이 유틸리티는 동시에 몇 개의 메모리카드나 UFD를 인식할 수 있나?\"  # 예시 질의\n",
        "answer = rag_chain.invoke(query)\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# 7️⃣ 결과 출력\n",
        "# -----------------------------------------------------\n",
        "print(\"질문:\", query)\n",
        "print(\"답변:\", answer.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e6140da",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "07b4620a-a094-42cb-a557-19c66fab6bc3"
        }
      },
      "source": [
        "#### ChatGPT vs RAG 챗봇 성능 비교 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "934fe7ed",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "7c7d88f4-cee9-47a7-881f-2c06f3ec0a4f"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== 질문 1 ===\n",
            "Q: 삼성 메모리 카드/UFD 인증 유틸리티에서 동시에 몇 개의 카드나 UFD를 인식할 수 있습니까?\n",
            "\n",
            "\u001b[91m[일반 ChatGPT 답변]\u001b[0m\n",
            "삼성 메모리 카드 및 UFD(USB 플래시 드라이브) 인증 유틸리티는 일반적으로 여러 개의 메모리 카드나 UFD를 동시에 인식할 수 있습니다. 그러나 동시에 인식할 수 있는 개수는 사용 중인 컴퓨터의 USB 포트 수와 드라이버의 성능에 따라 달라질 수 있습니다. 일반적으로 USB 포트가 충분하다면 여러 개의 장치를 동시에 연결하고 인식할 수 있습니다. \n",
            "\n",
            "정확한 개수는 사용 환경에 따라 다를 수 있으므로, 특정한 상황에서의 성능을 확인하려면 실제로 여러 개의 장치를 연결해 보거나 삼성의 공식 문서를 참조하는 것이 좋습니다.\n",
            "\n",
            "\u001b[94m[RAG 기반 답변]\u001b[0m\n",
            "삼성 메모리 카드/UFD 인증 유틸리티는 동시에 최대 8개의 카드를 인식할 수 있습니다.\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "=== 질문 2 ===\n",
            "Q: 삼성 메모리 카드/UFD 인증 유틸리티는 BitLocker가 활성화된 장치나 포맷되지 않은 장치를 인증할 수 있습니까?\n",
            "\n",
            "\u001b[91m[일반 ChatGPT 답변]\u001b[0m\n",
            "삼성 메모리 카드/UFD 인증 유틸리티는 일반적으로 BitLocker가 활성화된 장치나 포맷되지 않은 장치를 인증할 수 없습니다. BitLocker가 활성화된 장치는 암호화된 상태이기 때문에 인증 유틸리티가 해당 장치의 내용을 읽거나 검증할 수 없으며, 포맷되지 않은 장치 역시 파일 시스템이 없기 때문에 인증이 불가능합니다. 인증 유틸리티는 일반적으로 정상적으로 포맷되고 사용 가능한 상태의 장치에서 작동합니다.\n",
            "\n",
            "\u001b[94m[RAG 기반 답변]\u001b[0m\n",
            "삼성 메모리 카드/UFD 인증 유틸리티는 BitLocker가 활성화된 장치와 포맷되지 않은 장치를 인증할 수 없습니다.\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "=== 질문 3 ===\n",
            "Q: 삼성 메모리 카드/UFD 인증 유틸리티에서 지원되는 운영체제(OS) 버전은 무엇입니까?\n",
            "\n",
            "\u001b[91m[일반 ChatGPT 답변]\u001b[0m\n",
            "삼성 메모리 카드 및 UFD(USB 플래시 드라이브) 인증 유틸리티는 일반적으로 Windows 운영체제에서 지원됩니다. 구체적으로는 Windows 7, 8, 10, 11 등의 버전에서 사용할 수 있습니다. 그러나 최신 정보나 특정 버전의 지원 여부는 삼성 공식 웹사이트나 해당 유틸리티의 문서를 참조하는 것이 가장 정확합니다.\n",
            "\n",
            "\u001b[94m[RAG 기반 답변]\u001b[0m\n",
            "삼성 메모리 카드/UFD 인증 유틸리티에서 지원되는 운영체제(OS) 버전은 다음과 같습니다:\n",
            "- Windows 7 (32/64비트)\n",
            "- Windows 8 및 8.1 (32/64비트)\n",
            "- Windows 10 (32/64비트)\n",
            "\n",
            "----------------------------------\n"
          ]
        }
      ],
      "source": [
        "llm_base = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# ANSI 색상 코드\n",
        "RED = \"\\033[91m\"\n",
        "BLUE = \"\\033[94m\"\n",
        "RESET = \"\\033[0m\"\n",
        "\n",
        "\n",
        "# 비교할 질문 목록\n",
        "questions = [\n",
        "    \"삼성 메모리 카드/UFD 인증 유틸리티에서 동시에 몇 개의 카드나 UFD를 인식할 수 있습니까?\",\n",
        "    \"삼성 메모리 카드/UFD 인증 유틸리티는 BitLocker가 활성화된 장치나 포맷되지 않은 장치를 인증할 수 있습니까?\",\n",
        "    \"삼성 메모리 카드/UFD 인증 유틸리티에서 지원되는 운영체제(OS) 버전은 무엇입니까?\"\n",
        "]\n",
        "#성능 비교 실행\n",
        "\n",
        "for i, q in enumerate(questions, 1):\n",
        "    print(f\"\\n=== 질문 {i} ===\")\n",
        "    print(\"Q:\", q)\n",
        "    \n",
        "    # 기본 ChatGPT (비RAG)\n",
        "    base_answer = llm_base.invoke(q)\n",
        "    print(f\"\\n{RED}[일반 ChatGPT 답변]{RESET}\")\n",
        "    print(base_answer.content)\n",
        "    \n",
        "    # RAG 기반 ChatGPT\n",
        "    rag_answer = rag_chain.invoke(q)\n",
        "    print(f\"\\n{BLUE}[RAG 기반 답변]{RESET}\")\n",
        "    print(rag_answer.content)\n",
        "    \n",
        "    print(\"\\n----------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b93c399",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "fc739b70-6601-4075-9567-93bed7505051"
        }
      },
      "source": [
        "##  7. 웹 UI 연동\n",
        "### 🔹 Streamlit이란?\n",
        "- 파이썬 코드만으로 손쉽게 웹 애플리케이션을 만들 수 있는 프레임워크  \n",
        "- 데이터 과학, 머신러닝 프로젝트의 **UI 제작에 최적화**  \n",
        "- 복잡한 프론트엔드 기술(HTML, JS) 없이도 대화형 웹 페이지 제작 가능  \n",
        "\n",
        "### 🔹 실행 방법\n",
        "```bash\n",
        "streamlit run app.py\n",
        "```\n",
        "- `--server.port 8501` : 포트 지정  \n",
        "- `--server.address 0.0.0.0` : 외부 접속 허용  \n",
        "\n",
        "→ 예:  \n",
        "```bash\n",
        "streamlit run app.py --server.port 8501 --server.address 0.0.0.0\n",
        "```\n",
        "\n",
        "- 접속: `http://localhost:8501`  \n",
        "- 외부 네트워크: `http://<서버IP>:8501`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "226127ce",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "02cdda0d-8b3b-401f-b06b-c3d00c77daa0"
        }
      },
      "source": [
        "#### Streamlit 실행 테스트\n",
        "\n",
        "1. `app.py` 파일을 생성하고 다음 내용을 입력한다.\n",
        "\n",
        "```python\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"Hello Streamlit 👋\")\n",
        "st.write(\"Streamlit 앱이 정상적으로 실행되고 있습니다.\")\n",
        "```\n",
        "\n",
        "2. **터미널**에서 실행한다.\n",
        "\n",
        "```bash\n",
        "streamlit run app.py\n",
        "```\n",
        "\n",
        "3. 브라우저가 자동으로 열리며 `localhost:8501`에서 앱이 실행되는지 확인한다.\n",
        "\n",
        "4. 코드 수정 후 저장하면 브라우저가 자동으로 새로고침되는지 확인한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d96fb60c",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "5e136756-baea-4ca1-be22-ef4618d88739"
        }
      },
      "source": [
        "### Streamlit 기본 구조 및 구성요소"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6394e1a1",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "822b9c85-2f74-42aa-b320-59542995f6e4"
        }
      },
      "source": [
        "#### 입력 위젯 (Input Widgets)\n",
        "\n",
        "사용자 입력을 받는 UI 요소들이다.  \n",
        "모든 입력 위젯은 Streamlit 내부적으로 **자동 상태 저장(stateful)** 구조를 가진다.\n",
        "\n",
        "| 위젯 | 설명 | 예시 코드 |\n",
        "|------|------|-----------|\n",
        "| `st.text_input()` | 문자열 입력 | `name = st.text_input(\"이름 입력\")` |\n",
        "| `st.number_input()` | 숫자 입력 | `age = st.number_input(\"나이\", 0, 120)` |\n",
        "| `st.slider()` | 범위 선택 | `level = st.slider(\"난이도\", 1, 10, 5)` |\n",
        "| `st.selectbox()` | 드롭다운 선택 | `lang = st.selectbox(\"언어\", [\"Python\", \"R\", \"C++\"])` |\n",
        "| `st.checkbox()` | 체크박스 | `agree = st.checkbox(\"동의합니다\")` |\n",
        "| `st.file_uploader()` | 파일 업로드 | `file = st.file_uploader(\"CSV 업로드\")` |\n",
        "\n",
        "### 예시\n",
        "\n",
        "```python\n",
        "import streamlit as st\n",
        "\n",
        "st.header(\"입력 위젯 데모\")\n",
        "\n",
        "name = st.text_input(\"이름을 입력하세요\")\n",
        "age = st.number_input(\"나이\", min_value=0, max_value=120, value=25)\n",
        "lang = st.selectbox(\"언어 선택\", [\"Python\", \"R\", \"C++\"])\n",
        "submit = st.button(\"확인\")\n",
        "\n",
        "if submit:\n",
        "    st.success(f\"{name}님은 {age}세이며, {lang}을(를) 사용합니다.\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88cf6134",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "268365f6-6795-447a-a5bf-76f5d154fed3"
        }
      },
      "source": [
        "### 출력 요소 (Output Components)\n",
        " \n",
        "Streamlit은 데이터를 텍스트, 표, 차트 등 다양한 형태로 표현할 수 있습니다.\n",
        "\n",
        "| 출력 함수 | 용도 | 예시 |\n",
        "|------------|------|------|\n",
        "| `st.write()` | 텍스트, 변수, 데이터프레임 자동 처리 | `st.write(df)` |\n",
        "| `st.dataframe()` | 스크롤 가능한 표 | `st.dataframe(df)` |\n",
        "| `st.table()` | 정적 표 | `st.table(df.head())` |\n",
        "| `st.json()` | JSON 포맷 출력 | `st.json({\\\"name\\\": \\\"AI\\\", \\\"ver\\\": 1.0})` |\n",
        "| `st.line_chart()` | 선형 차트 | `st.line_chart(df)` |\n",
        "| `st.bar_chart()` | 막대 차트 | `st.bar_chart(df)` |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d3dd5bf",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "77571668-3159-416a-83b5-c9650950908e"
        }
      },
      "source": [
        "```python\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "st.header(\"출력 요소 예제\")\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    x: np.arange(1, 6),\n",
        "    y: np.random.randint(1, 100, 5)\n",
        "})\n",
        "\n",
        "st.dataframe(data)\n",
        "st.bar_chart(data.set_index(x))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58d9e711",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "d1f97128-dacf-4a52-bd9a-af1bcbe8d350"
        }
      },
      "source": [
        "### 디자인 템플릿 및 UI 활용 팁 (NEW)\n",
        "\n",
        "이 장에서는 Streamlit 앱의 **디자인 완성도와 사용자 경험(UX)** 을 향상시키는 기법을 학습합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac9a6fae",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "00c063ce-00ce-42de-a988-7bf6ddec5186"
        }
      },
      "source": [
        "디자인은 처음부터 새로 만들기보다, **기존 템플릿을 참고하고 커스터마이징**하는 것이 훨씬 효율적입니다.\n",
        "\n",
        " **원칙:**  \n",
        "1. 처음에는 완성된 구조를 복제하라.  \n",
        "2. 필요할 때만 커스터마이징하라.  \n",
        "3. 시각보다는 기능과 명료성을 우선하라.\n",
        "\n",
        "### 참고 자료\n",
        "- Streamlit 공식 갤러리: [https://streamlit.io/gallery](https://streamlit.io/gallery)\n",
        "- GitHub: `awesome-streamlit`, `streamlit-extras` 등\n",
        "- 커뮤니티 오픈소스: HuggingFace Spaces, Streamlit Community Cloud"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f136e43f",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "7dbc2aad-90f2-4e51-b3d1-600074359dbd"
        }
      },
      "source": [
        "#### 🔹 참고 : 추후 배포 방법\n",
        "1. **도메인 구매** (가비아, GoDaddy, AWS Route53 등)  \n",
        "2. **클라우드 서버** (AWS, GCP, Naver Cloud 등)에 배포  \n",
        "3. **Nginx/Apache Reverse Proxy 설정**  \n",
        "   - `http://chat.my-domain.com` 으로 접근 가능하게 구성"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44cb2602",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "b78fb7ef-b9bd-42d1-8ad4-ee7d98b10370"
        }
      },
      "source": [
        "##  8. 복습문제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a67020",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "e5ec13e6-7c69-441e-af05-2bdde3f1862f"
        }
      },
      "source": [
        "### 문제 1. API 키를 `.env` 파일에 보관하는 이유는 무엇인가요? \n",
        "<details>\n",
        "<summary>정답 보기</summary>  \n",
        "\n",
        "- **보안성**: 키 하드코딩/깃 커밋 방지 → 외부 유출 리스크 감소\n",
        "- **환경 분리**: 로컬/스테이징/프로덕션 별로 키 교체 용이\n",
        "- **자동화**: CI/CD에서 시크릿 관리와 연동 쉬움\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05bc0985",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "a67d9917-8052-4f69-8e23-bd560cd35f24"
        }
      },
      "outputs": [],
      "source": [
        "### 여기에 정답을 작성해보세요"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "983ec964",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "dc5491fc-3c5b-4ad3-a90a-3acf5b0df99f"
        }
      },
      "source": [
        "### 문제 2. **프롬프트 설계**: \n",
        "\n",
        "\"너는 용접 전문가야\"라는 시스템 프롬프트를 넣고, 사용자가 배관 부식 원인을 물었을 때 기술적인 답변을 출력하는 체인을 작성해보세요.  \n",
        "\n",
        "<details>\n",
        "<summary>정답 보기</summary>\n",
        "\n",
        "```python \n",
        "from dotenv import load_dotenv              # .env 파일에서 환경변수(OPENAI_API_KEY) 불러오기\n",
        "import os                                   # OS 환경변수 접근\n",
        "from langchain_core.prompts import ChatPromptTemplate  # 프롬프트 템플릿(변수 삽입/재사용)\n",
        "from langchain_openai import ChatOpenAI                # OpenAI 대화형 LLM 래퍼\n",
        "from langchain_core.output_parsers import StrOutputParser  # 모델 응답을 문자열로 파싱\n",
        "\n",
        "# ===========================================\n",
        "# 2) 환경변수 로드\n",
        "# ===========================================\n",
        "load_dotenv()                               # 현재 작업 디렉토리의 .env를 로드\n",
        "# os.getenv(\"OPENAI_API_KEY\")               # 내부적으로 ChatOpenAI가 환경변수를 읽음\n",
        "\n",
        "# ===========================================\n",
        "# 3) 프롬프트 템플릿 정의\n",
        "#    - System: 모델 역할을 '용접 전문가'로 고정\n",
        "#    - User: 실습 시 입력될 질문 자리표시자 {question}\n",
        "# ===========================================\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"너는 용접 전문가이자 재료공학 엔지니어야. 한국어로 간결하지만 정확하게 답변해. \"\n",
        "               \"표준/코드(AWS/ASME/KS)나 공정 용어는 정확히 사용해.\"),\n",
        "    (\"user\", \"{question}\")\n",
        "])\n",
        "\n",
        "# ===========================================\n",
        "# 4) 모델 & 파서 준비\n",
        "# ===========================================\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")   # 필요 시 gpt-4o 등으로 교체 가능\n",
        "parser = StrOutputParser()                   # 메시지를 최종 문자열로 변환\n",
        "\n",
        "# ===========================================\n",
        "# 5) LCEL로 체인 구성: Prompt -> Model -> Parser\n",
        "# ===========================================\n",
        "chain = prompt | model | parser\n",
        "\n",
        "# ===========================================\n",
        "# 6) 실행 예시\n",
        "# ===========================================\n",
        "question = \"SUS304 배관에서 담수 조건 핀홀 부식 원인을 설명해줘. 예방책도 제시해줘.\"\n",
        "answer = chain.invoke({\"question\": question})  # 자리표시자에 question 바인딩\n",
        "print(answer)                                  # 최종 텍스트 출력\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6d3df3b",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "9abe1508-c764-4fbf-ae05-f8591165ee3c"
        }
      },
      "outputs": [],
      "source": [
        "### 여기에 정답을 작성해보세요\n",
        "from dotenv import load_dotenv              # .env 파일에서 환경변수(OPENAI_API_KEY) 불러오기\n",
        "import os                                   # OS 환경변수 접근\n",
        "from langchain_core.prompts import ChatPromptTemplate  # 프롬프트 템플릿(변수 삽입/재사용)\n",
        "from langchain_openai import ChatOpenAI                # OpenAI 대화형 LLM 래퍼\n",
        "from langchain_core.output_parsers import StrOutputParser  # 모델 응답을 문자열로 파싱"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36f9d9e7",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "8dbf1e22-743b-4305-a987-b8aa83fe3e9b"
        }
      },
      "source": [
        "### 문제 3. **대화 기억**: \n",
        "\n",
        "사용자의 첫 질문에 \"용접의 종류\"를 답변한 뒤, 두 번째 질문에 \"방금 말한 종류 중 하나를 설명해\"라고 했을 때  \n",
        "올바르게 이어질 수 있도록 메모리를 적용해보세요. \n",
        "\n",
        "<details>\n",
        "<summary>정답 보기</summary>\n",
        "\n",
        "```python \n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder  # 히스토리용 플레이스홀더\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# ===========================================\n",
        "# 2) 환경변수 로드\n",
        "# ===========================================\n",
        "load_dotenv()\n",
        "\n",
        "# ===========================================\n",
        "# 3) 대화 히스토리 컨테이너 (간단 리스트)\n",
        "#    - (role, content) 튜플 목록으로 관리\n",
        "#    - 실제 프로덕션에선 ConversationBufferMemory 등을 사용할 수 있음\n",
        "# ===========================================\n",
        "history = []  # 예: [(\"user\",\"...\"), (\"assistant\",\"...\"), ...]\n",
        "\n",
        "# ===========================================\n",
        "# 4) 프롬프트 템플릿\n",
        "#    - MessagesPlaceholder(\"history\")를 이용해 멀티턴 히스토리 삽입\n",
        "# ===========================================\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"너는 용접 전문가야. 한국어로 단계적으로 설명해.\"),\n",
        "    MessagesPlaceholder(variable_name=\"history\"),  # 여기에 이전 턴들 삽입\n",
        "    (\"user\", \"{input}\")                             # 현재 사용자 질문\n",
        "])\n",
        "\n",
        "# ===========================================\n",
        "# 5) 모델 & 파서 & 체인 구성\n",
        "# ===========================================\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "parser = StrOutputParser()\n",
        "chain = prompt | model | parser\n",
        "\n",
        "# ===========================================\n",
        "# 6) 1차 질문/응답\n",
        "# ===========================================\n",
        "user_q1 = \"용접의 대표적인 공정 3가지를 요약해줘.\"\n",
        "assistant_a1 = chain.invoke({\"history\": history, \"input\": user_q1})\n",
        "print(\"Assistant(1):\", assistant_a1)\n",
        "\n",
        "# 히스토리 업데이트 (다음 턴에 맥락으로 사용)\n",
        "history.append((\"user\", user_q1))\n",
        "history.append((\"assistant\", assistant_a1))\n",
        "\n",
        "# ===========================================\n",
        "# 7) 2차 질문/응답 (이전 답을 참조하도록 유도)\n",
        "# ===========================================\n",
        "user_q2 = \"방금 말한 3가지 중 FCAW를 장단점 중심으로 자세히 설명해줘.\"\n",
        "assistant_a2 = chain.invoke({\"history\": history, \"input\": user_q2})\n",
        "print(\"Assistant(2):\", assistant_a2)\n",
        "\n",
        "# 히스토리 업데이트(선택)\n",
        "history.append((\"user\", user_q2))\n",
        "history.append((\"assistant\", assistant_a2))\n",
        "\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a76508",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "699a19ad-c100-4a1a-8f67-3ecb25d05848"
        }
      },
      "outputs": [],
      "source": [
        "### 여기에 정답을 작성해보세요\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad602c9a",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "23ac7358-19f6-4531-8a9e-89d4268781fa"
        }
      },
      "source": [
        "### 문제 4. **문서 기반 챗봇 확장**: FAISS에 여러 PDF 문서를 임포트해 검색 가능한 챗봇을 만들어보세요.\n",
        "\n",
        "<details>\n",
        "<summary>정답 보기</summary>\n",
        "\n",
        "```python \n",
        "# ===========================================\n",
        "# 1) 라이브러리 임포트\n",
        "# ===========================================\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from langchain.text_splitter import CharacterTextSplitter        # 문서 청크 분할\n",
        "from langchain_community.vectorstores import FAISS               # 벡터DB로 FAISS 사용\n",
        "from langchain_openai import OpenAIEmbeddings                    # OpenAI 임베딩\n",
        "from langchain_core.prompts import ChatPromptTemplate            # RAG 프롬프트\n",
        "from langchain_openai import ChatOpenAI                          # LLM\n",
        "from langchain_core.output_parsers import StrOutputParser        # 출력 파서\n",
        "\n",
        "# (선택) PDF 로더를 쓰려면 pypdf 설치 후 아래 임포트 가능\n",
        "# from langchain_community.document_loaders import PyPDFLoader   # pip install pypdf\n",
        "\n",
        "# ===========================================\n",
        "# 2) 환경변수 로드\n",
        "# ===========================================\n",
        "load_dotenv()\n",
        "\n",
        "# ===========================================\n",
        "# 3) 원문 수집\n",
        "#    - 간단히 텍스트 리스트로 예시\n",
        "#    - PDF 사용 시: loader = PyPDFLoader(\"file.pdf\"); docs = loader.load()\n",
        "# ===========================================\n",
        "raw_texts = [\n",
        "    \"SUS304는 오스테나이트계 스테인리스로 내식성이 우수하나 염화이온 환경에선 틈부식 위험이 존재한다.\",\n",
        "    \"FCAW(Flux-Cored Arc Welding)는 고생산성 공정으로 야외 시공에서 이점이 있지만 슬래그 제거가 필요하다.\",\n",
        "    \"ASME Section IX는 용접 절차 및 성능시험에 대한 요건을 규정한다.\"\n",
        "]\n",
        "\n",
        "# ===========================================\n",
        "# 4) 텍스트 → Document로 변환 및 분할\n",
        "# ===========================================\n",
        "splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
        "documents = splitter.create_documents(raw_texts)  # 리스트[str] → 리스트[Document]\n",
        "\n",
        "# ===========================================\n",
        "# 5) 임베딩 & 벡터DB 색인\n",
        "# ===========================================\n",
        "embeddings = OpenAIEmbeddings()           # OpenAI 임베딩 사용\n",
        "vectordb = FAISS.from_documents(documents, embeddings)  # 인메모리 FAISS 인덱스 생성\n",
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})  # 상위 3개 유사 청크 검색\n",
        "\n",
        "# ===========================================\n",
        "# 6) 간단한 RAG 프롬프트 & LLM\n",
        "#    - 검색 결과를 context로 주입해 정확한 답을 유도\n",
        "# ===========================================\n",
        "rag_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"너는 재료/용접 전문가야. 아래 문맥(context)을 근거로 질문에 답하되, \"\n",
        "     \"모르면 모른다고 말해. 추측하지 마라.\\n\\n[CONTEXT]\\n{context}\\n\"),\n",
        "    (\"user\", \"{question}\")\n",
        "])\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# ===========================================\n",
        "# 7) RAG 질의 함수\n",
        "# ===========================================\n",
        "def rag_answer(question: str) -> str:\n",
        "    # (1) 검색\n",
        "    docs = retriever.get_relevant_documents(question)\n",
        "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
        "    # (2) 생성\n",
        "    chain = rag_prompt | llm | parser\n",
        "    return chain.invoke({\"context\": context, \"question\": question})\n",
        "\n",
        "# ===========================================\n",
        "# 8) 실행 예시\n",
        "# ===========================================\n",
        "q = \"야외 시공에서 FCAW의 장점은 뭐야? 틈부식 관련 주의사항도 알려줘.\"\n",
        "print(rag_answer(q))\n",
        "\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7472476",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "ae4e5172-134f-484c-bca2-9149c78c6ff7"
        }
      },
      "outputs": [],
      "source": [
        "### 여기에 정답을 작성해보세요\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from langchain.text_splitter import CharacterTextSplitter        # 문서 청크 분할\n",
        "from langchain_community.vectorstores import FAISS               # 벡터DB로 FAISS 사용\n",
        "from langchain_openai import OpenAIEmbeddings                    # OpenAI 임베딩\n",
        "from langchain_core.prompts import ChatPromptTemplate            # RAG 프롬프트\n",
        "from langchain_openai import ChatOpenAI                          # LLM\n",
        "from langchain_core.output_parsers import StrOutputParser        # 출력 파서"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02bb80d6",
      "metadata": {
        "cell_watermark": {
          "hash": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
          "date": "2025-10-28",
          "uuid": "acdd8e06-e797-43b0-ac3b-b926500b6941"
        }
      },
      "source": [
        "##  9. 최종 프로젝트\n",
        "\n",
        "직접 챗봇을 기획하고 구현하는 프로젝트를 수행합니다.  \n",
        "아래의 예시 중 하나를 선택하거나, 자신만의 주제를 정해도 좋습니다.\n",
        "\n",
        "- 전공 Q&A 챗봇: 전공 분야의 질문에 자동으로 답변하는 챗봇\n",
        "- 특정 문서 기반 검색 챗봇: 특정 보고서나 매뉴얼을 기반으로 정보를 찾아주는 챗봇\n",
        "- FAQ 자동응답 챗봇: 자주 묻는 질문에 자동으로 응답하는 고객지원형 챗봇\n",
        "\n",
        "**프로젝트 결과물**:  \n",
        "  - 완성된 챗봇 웹 애플리케이션\n",
        "    - 실제로 동작 가능한 형태의 챗봇 웹 서비스 구현  \n",
        "    - **Streamlit**, **Flask**, **React** 등 어떤 프레임워크를 사용해도 무방\n",
        "\n",
        "  - GitHub 저장소 혹은 실행파일\n",
        "    - 구현한 코드와 실행 방법(`README.md`)을 포함하여 GitHub에 업로드 후 링크를 제출\n",
        "    - 혹은 작성한 코드를 압축파일 형태로 제출\n",
        "    - **Tip:** README.md에 챗봇 소개, 사용 방법, 기술 스택, 실행 예시 스크린샷을 포함하면 평가에 도움이 됩니다\n",
        "\n",
        "**제출 방법**\n",
        "\n",
        "- **제출 기한:** 수업 마지막날 밤 12시까지  \n",
        "- **제출 이메일:** `rlaalstn1504@naver.com` "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "encoded_email": "cmxhYWxzdG4xNTA0QG5hdmVyLmNvbQ==",
    "inserted_date": "2025-10-28",
    "filename": "MuydvOywqC5pcHluYg=="
  },
  "nbformat": 4,
  "nbformat_minor": 5
}